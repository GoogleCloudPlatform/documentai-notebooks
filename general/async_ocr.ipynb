{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8e0582b",
   "metadata": {},
   "source": [
    "# Document AI OCR (async)\n",
    "\n",
    "This notebook shows you how to do OCR on documents using the Google Cloud DocumentAI API asynchronously. For the asynchronous request the GCS URI or GCS bucket with prefix will be send for one or more documents and an operation ID is returned. The operation status will be checked until the result is available. The response is then visualized showing the preprocessed (e.g. rotated) image together with bounding boxes for block, paragraph, line and token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a48ea7",
   "metadata": {},
   "source": [
    "## Set your Processor Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870dd41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"YOUR_GCP_PROJECT_ID\"\n",
    "LOCATION = \"eu\"  # Format is 'us' or 'eu'\n",
    "PROCESSOR_ID = \"YOUR_DOCAI_PROCESSOR_ID\"  # Create OCR processor in Cloud Console\n",
    "\n",
    "# check supported file types at https://cloud.google.com/document-ai/docs/processors-list#processor_doc-ocr\n",
    "SUPPORTED_FILE_TYPES = [\"PDF\", \"TIF\", \"TIFF\", \"GIF\", \"JPG\", \"JPEG\", \"PNG\", \"BMP\", \"WEBP\"]\n",
    "\n",
    "# Sample invoices are stored in gs://cloud-samples-data/documentai/async_invoices/\n",
    "GCS_INPUT_BUCKET = 'cloud-samples-data'\n",
    "GCS_INPUT_PREFIX = 'documentai'\n",
    "\n",
    "# The output bucket will be created if it does not exist\n",
    "GCS_OUTPUT_BUCKET = PROJECT_ID + '-dai-temp'\n",
    "GCS_OUTPUT_PREFIX = 'output'\n",
    "\n",
    "TIMEOUT = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af37cfe3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e99b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary Python libraries and restart your kernel after.\n",
    "!pip install --quiet -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628a5250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import documentai_v1 as documentai\n",
    "from google.cloud import storage\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from typing import List\n",
    "import mimetypes\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe2d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureType(Enum):\n",
    "    PAGE = 1\n",
    "    BLOCK = 2\n",
    "    PARA = 3\n",
    "    LINE = 4\n",
    "    TOKEN = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd77f821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process(gcs_output_uri: str, gcs_input_uris: List[str] = [], gcs_input_uri_prefix: str = \"\", skip_human_review: bool = False) -> dict:\n",
    "    \"\"\"Asynchronous (batch) process documents using REST API.\n",
    "    \n",
    "    Processes documents stored on Google Cloud Storage (GCS) either by list of GCS URIs or GCS URI Prefix and returns operation status.\n",
    "    Optionally allows to skip human review if enabled for the processor.\n",
    "    See details at\n",
    "    https://cloud.google.com/document-ai/docs/reference/rest/v1/projects.locations.processors/batchProcess\n",
    "    \n",
    "    Args:\n",
    "        gcs_output_uri: GCS URI to save output JSON to (e.g. 'gs://bucket/output').\n",
    "        gcs_input_uris: List of GCS URIs (e.g. ['gs://bucket1/file1.jpg','gs://bucket2/file2.pdf'])\n",
    "        gcs_input_uri_prefix: GCS URI Prefix (e.g. 'gs://bucket/prefix') to be checked for supported files.\n",
    "        skip_human_review: Optional; Whether Human Review feature should be skipped for this request. Default to false.\n",
    "        \n",
    "    Returns:\n",
    "        An operation reflecting the status of the batch process operation.\n",
    "        See details at\n",
    "        https://cloud.google.com/document-ai/docs/reference/rest/v1/projects.locations.operations#Operation\n",
    "    \"\"\"\n",
    "     \n",
    "    # Instantiate a Document AI client\n",
    "    client_options = {\"api_endpoint\": f\"{LOCATION}-documentai.googleapis.com\"}\n",
    "    client = documentai.DocumentProcessorServiceClient(client_options = client_options)\n",
    "    \n",
    "    # Instantiate a Storage Client\n",
    "    storage_client = storage.Client()\n",
    "    \n",
    "    input_config = None\n",
    "    \n",
    "    if len(gcs_input_uris) > 0:\n",
    "        documents = []\n",
    "        for gcs_input_uri in gcs_input_uris:\n",
    "            if not gcs_input_uri.startswith(\"gs://\"):\n",
    "                raise Exception(f\"gcs_input_uri {gcs_input_uri} missing gs:// prefix.\")\n",
    "            \n",
    "            mime_type = mimetypes.guess_type(gcs_input_uri)[0]\n",
    "            if not mime_type:\n",
    "                raise Exception(f\"MIME type of gcs_input_uri {gcs_input_uri_prefix} could not be guessed from file extension.\")\n",
    "            \n",
    "            document = {\"gcs_uri\": gcs_input_uri, \"mime_type\": mime_type}\n",
    "            documents.append(document)\n",
    "            \n",
    "        gcs_documents = documentai.GcsDocuments(documents=documents)\n",
    "        input_config = documentai.BatchDocumentsInputConfig(gcs_documents=gcs_documents)\n",
    "    elif gcs_input_uri_prefix:\n",
    "        if not gcs_input_uri_prefix.startswith(\"gs://\"):\n",
    "            raise Exception(f\"gcs_input_uri_prefix {gcs_input_uri_prefix} missing gs:// prefix.\")\n",
    "        gcs_prefix = documentai.GcsPrefix(gcs_uri_prefix = gcs_input_uri_prefix)\n",
    "        input_config = documentai.BatchDocumentsInputConfig(gcs_prefix = gcs_prefix)\n",
    "    else:\n",
    "        raise Exception(\"Neither gcs_input_uris nor gcs_input_uri_prefix specified.\")\n",
    "    \n",
    "    output_bucket = storage.Bucket(client = storage_client, name = GCS_OUTPUT_BUCKET)\n",
    "    if not output_bucket.exists():\n",
    "        print(f\"Bucket {GCS_OUTPUT_BUCKET} does not exist, creating it in location {LOCATION}.\")\n",
    "        output_bucket.create(location = LOCATION)\n",
    "    \n",
    "    # The full resource name of the processor, e.g.:\n",
    "    # projects/project-id/locations/location/processor/processor-id\n",
    "    name = f\"projects/{PROJECT_ID}/locations/{LOCATION}/processors/{PROCESSOR_ID}\"\n",
    "    \n",
    "    # Where to write results\n",
    "    destination_uri = f\"gs://{GCS_OUTPUT_BUCKET}/{GCS_OUTPUT_PREFIX}/\"\n",
    "    output_config = documentai.DocumentOutputConfig(\n",
    "        gcs_output_config={\"gcs_uri\": destination_uri}\n",
    "    )\n",
    "    \n",
    "    # Batch Process document\n",
    "    batch_process_request = documentai.types.document_processor_service.BatchProcessRequest(\n",
    "        name=name,\n",
    "        input_documents=input_config,\n",
    "        document_output_config=output_config,\n",
    "    )\n",
    "    \n",
    "    return client.batch_process_documents(request = batch_process_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbecac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_bounds(page, feature):\n",
    "    # [START vision_document_text_tutorial_detect_bounds]\n",
    "    \"\"\"Returns document bounds given the OCR output page.\"\"\"\n",
    "\n",
    "    bounds = []\n",
    "\n",
    "    # Collect specified feature bounds by enumerating all document features\n",
    "    if (feature == FeatureType.BLOCK):\n",
    "        for block in page.blocks:\n",
    "            if not block.layout.bounding_poly.vertices:\n",
    "                block.layout.bounding_poly.vertices = []\n",
    "                for normalized_vertice in block.layout.bounding_poly.normalized_vertices:\n",
    "                    block.layout.bounding_poly.vertices.append(documentai.Vertex(x=int(normalized_vertice.x * page.image.width),y=int(normalized_vertice.y * page.image.height)))\n",
    "            bounds.append(block.layout.bounding_poly)\n",
    "    if (feature == FeatureType.PARA):\n",
    "        for paragraph in page.paragraphs:\n",
    "            if not paragraph.layout.bounding_poly.vertices:\n",
    "                paragraph.layout.bounding_poly.vertices = []\n",
    "                for normalized_vertice in paragraph.layout.bounding_poly.normalized_vertices:\n",
    "                    paragraph.layout.bounding_poly.vertices.append(documentai.Vertex(x=int(normalized_vertice.x * page.image.width),y=int(normalized_vertice.y * page.image.height)))\n",
    "            bounds.append(paragraph.layout.bounding_poly)\n",
    "    if (feature == FeatureType.LINE):        \n",
    "        for line in page.lines:\n",
    "            if not line.layout.bounding_poly.vertices:\n",
    "                line.layout.bounding_poly.vertices = []\n",
    "                for normalized_vertice in line.layout.bounding_poly.normalized_vertices:\n",
    "                    line.layout.bounding_poly.vertices.append(documentai.Vertex(x=int(normalized_vertice.x * page.image.width),y=int(normalized_vertice.y * page.image.height)))\n",
    "            bounds.append(line.layout.bounding_poly)\n",
    "    if (feature == FeatureType.TOKEN):        \n",
    "        for token in page.tokens:\n",
    "            if not token.layout.bounding_poly.vertices:\n",
    "                token.layout.bounding_poly.vertices = []\n",
    "                for normalized_vertice in token.layout.bounding_poly.normalized_vertices:\n",
    "                    token.layout.bounding_poly.vertices.append(documentai.Vertex(x=int(normalized_vertice.x * page.image.width),y=int(normalized_vertice.y * page.image.height)))\n",
    "            bounds.append(token.layout.bounding_poly)\n",
    "\n",
    "\n",
    "    # The list `bounds` contains the coordinates of the bounding boxes.\n",
    "    # [END vision_document_text_tutorial_detect_bounds]\n",
    "    return bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9cca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(image, bounds, color, width):\n",
    "    \"\"\"Draw a border around the image using the hints in the vector list.\"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for bound in bounds:\n",
    "        points = (\n",
    "            (bound.vertices[0].x, bound.vertices[0].y),\n",
    "            (bound.vertices[1].x, bound.vertices[1].y),\n",
    "            (bound.vertices[2].x, bound.vertices[2].y),\n",
    "            (bound.vertices[3].x, bound.vertices[3].y),\n",
    "            (bound.vertices[0].x, bound.vertices[0].y)\n",
    "        )\n",
    "        draw.line(points,fill=color,width=width,joint='curve')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9575cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_doc_text(page):  \n",
    "    image = Image.open(io.BytesIO(page.image.content))\n",
    "    \n",
    "    # this will draw the bounding boxes for block, paragraph, line and token\n",
    "    bounds = get_page_bounds(page, FeatureType.BLOCK)\n",
    "    draw_boxes(image, bounds, color='blue', width=8)\n",
    "    bounds = get_page_bounds(page, FeatureType.PARA)\n",
    "    draw_boxes(image, bounds, color='red',width=6)\n",
    "    bounds = get_page_bounds(page, FeatureType.LINE)\n",
    "    draw_boxes(image, bounds, color='yellow',width=4)\n",
    "    bounds = get_page_bounds(page, FeatureType.TOKEN)\n",
    "    draw_boxes(image, bounds, color='green',width=2)\n",
    "        \n",
    "    image.show()\n",
    "    \n",
    "    # uncomment if you want to save the image with bounding boxes locally\n",
    "    #image.save(document.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c100dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the image should not be necessary and requires opencv which has a lot of dependencies\n",
    "\n",
    "def transform_image(page):\n",
    "    # only install depedencies when necessary\n",
    "    !sudo apt -qq install -y python3-opencv\n",
    "    !pip install --quiet opencv-python \n",
    "\n",
    "    import cv2\n",
    "\n",
    "    img_stream = io.BytesIO(page.image.content)\n",
    "    img = cv2.imdecode(np.frombuffer(img_stream.read(), np.uint8), 1)\n",
    "\n",
    "    matrix = None    \n",
    "    data = page.transforms[0].data\n",
    "    rows = page.transforms[0].rows\n",
    "    cols = page.transforms[0].cols\n",
    "    \n",
    "    if page.transforms[0].type_ == 0:\n",
    "        matrix = np.reshape(np.frombuffer(data, np.uint8), (rows, cols))\n",
    "    elif page.transforms[0].type_ == 1:\n",
    "        matrix = np.reshape(np.frombuffer(data, np.int8), (rows, cols))\n",
    "    elif page.transforms[0].type_ == 2:\n",
    "        matrix = np.reshape(np.frombuffer(data, np.uint16), (rows, cols))\n",
    "    elif page.transforms[0].type_ == 3:\n",
    "        matrix = np.reshape(np.frombuffer(data, np.int16), (rows, cols))\n",
    "    elif page.transforms[0].type_ == 4:\n",
    "        matrix = np.reshape(np.frombuffer(data, np.int32), (rows, cols))\n",
    "    elif page.transforms[0].type_ == 5:\n",
    "        matrix = np.reshape(np.frombuffer(data, np.float32), (rows, cols))\n",
    "    elif page.transforms[0].type_ == 6:\n",
    "        matrix = np.reshape(np.frombuffer(data, np.float64), (rows, cols))\n",
    "    elif page.transforms[0].type_ == 7:\n",
    "        matrix = np.reshape(np.frombuffer(data, np.float16), (rows, cols))\n",
    "    \n",
    "    # TODO: check rows and cols and implement warpPerspective for 3x3, throw error if not 2x3 or 3x3\n",
    "    \n",
    "    # the scale factor is required as the transformed image will be larger than the source image\n",
    "    scale_factor = 3\n",
    "    \n",
    "    if rows == 2 and cols == 3:\n",
    "        transformed_img = cv2.warpAffine(img, matrix, (page.image.width * scale_factor, page.image.height * scale_factor))\n",
    "    elif rows == 3 and cols == 3:\n",
    "        transformed_img = cv2.warpPerspective(img, matrix, (page.image.width * scale_factor, page.image.height * scale_factor))\n",
    "        \n",
    "    # trim image and remove black border\n",
    "    gray = cv2.cvtColor(transformed_img,cv2.COLOR_BGR2GRAY)\n",
    "    _,thresh = cv2.threshold(gray,1,255,cv2.THRESH_BINARY)\n",
    "    contours,hierarchy = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnt = contours[0]\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    transformed_img = transformed_img[y:y+h,x:x+w]\n",
    "    \n",
    "    content = cv2.imencode('.jpg', transformed_img)[1].tobytes()\n",
    "    height, width, _ = transformed_img.shape\n",
    "    page.image = documentai.Document.Page.Image(content=content, mime_type=page.image.mime_type, width=width, height=height)\n",
    "    return page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e798581b",
   "metadata": {},
   "source": [
    "### Process documents asynchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70593556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_gcs_samples():\n",
    "    gcs_input_uri_prefix = f\"gs://{GCS_INPUT_BUCKET}/{GCS_INPUT_PREFIX}\"\n",
    "    gcs_output_uri = f\"gs://{GCS_OUTPUT_BUCKET}/{GCS_OUTPUT_PREFIX}\"\n",
    "    print(f\"Processing all documents at {gcs_input_uri_prefix}\")\n",
    "    operation = batch_process(gcs_input_uri_prefix = gcs_input_uri_prefix, gcs_output_uri = gcs_output_uri)\n",
    "    \n",
    "    operation_id = operation._operation.name.split('/')[-1]\n",
    "    \n",
    "    print(f\"Operation ID: {operation_id}\")\n",
    "    \n",
    "    # Wait for the operation to finish\n",
    "    operation.result(timeout=TIMEOUT)\n",
    "            \n",
    "    # Instantiate a Storage Client\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    bucket = storage.Bucket(client = storage_client, name = GCS_OUTPUT_BUCKET)\n",
    "    blob_list = list(bucket.list_blobs(prefix=f\"{GCS_OUTPUT_PREFIX}/{operation_id}\"))\n",
    "\n",
    "    for i, blob in enumerate(blob_list):\n",
    "        # If JSON file, download the contents of this blob as a bytes object.\n",
    "        if \".json\" in blob.name:\n",
    "            blob_as_bytes = blob.download_as_string()\n",
    "\n",
    "            document = documentai.types.Document.from_json(blob_as_bytes)\n",
    "\n",
    "            # For a full list of Document object attributes, please reference this page:\n",
    "            # https://cloud.google.com/document-ai/docs/reference/rpc/google.cloud.documentai.v1#document\n",
    "            \n",
    "            for page in document.pages:\n",
    "                # TODO: remove once b/196544985 is fixed\n",
    "                if page.transforms:\n",
    "                    page = transform_image(page)\n",
    "\n",
    "                print(f\"Rendering file {blob.name} - Page {page.page_number}/{len(document.pages)}\")\n",
    "                render_doc_text(page=page)\n",
    "       \n",
    "            #remove blob, uncomment if you want to inspect the output json\n",
    "            print(f\"Deleting object {blob.name}\")\n",
    "            blob.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1138b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_process_gcs_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b89b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m76",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m76"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
