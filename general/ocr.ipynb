{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfb775f8",
   "metadata": {},
   "source": [
    "# Document AI OCR (sync)\n",
    "\n",
    "This notebook shows you how to do OCR on documents using the Google Cloud DocumentAI API synchronously. For the synchronous request the document content will be send as bytes and the program will block until it receives the response. The response is then visualized showing the preprocessed (e.g. rotated) image together with bounding boxes for block, paragraph, line and token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e465c307",
   "metadata": {},
   "source": [
    "## Set your Processor Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5dea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"YOUR_GCP_PROJECT_ID\"\n",
    "LOCATION = \"eu\"  # Format is 'us' or 'eu'\n",
    "PROCESSOR_ID = \"YOUR_DOCAI_PROCESSOR_ID\"  # Create OCR processor in Cloud Console\n",
    "\n",
    "# check supported file types at https://cloud.google.com/document-ai/docs/processors-list#processor_doc-ocr\n",
    "SUPPORTED_FILE_TYPES = [\"PDF\", \"TIF\", \"TIFF\", \"GIF\", \"JPG\", \"JPEG\", \"PNG\", \"BMP\", \"WEBP\"]\n",
    "\n",
    "# Sample invoices are stored in gs://cloud-samples-data/documentai/async_invoices/\n",
    "GCS_INPUT_BUCKET = 'cloud-samples-data'\n",
    "GCS_INPUT_PREFIX = 'documentai'\n",
    "\n",
    "LOCAL_INPUT_PATH = '../resources/general'\n",
    "\n",
    "TIMEOUT = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186f7e75",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd1b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary Python libraries and restart your kernel after.\n",
    "!pip install --quiet -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3379dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import documentai_v1 as documentai\n",
    "from google.cloud import storage\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfinterp import resolve1\n",
    "\n",
    "import mimetypes\n",
    "from pathlib import Path\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f7ade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureType(Enum):\n",
    "    PAGE = 1\n",
    "    BLOCK = 2\n",
    "    PARA = 3\n",
    "    LINE = 4\n",
    "    TOKEN = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40a8b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(content: bytes, mime_type: str, skip_human_review: bool = False) -> dict:\n",
    "    \"\"\"Synchronous (online) process document using REST API.\n",
    "    \n",
    "    Processes document content with given mime type and blocks until result is returned.\n",
    "    Optionally allows to skip human review if enabled for the processor.\n",
    "    See details at\n",
    "    https://cloud.google.com/document-ai/docs/reference/rest/v1/projects.locations.processors/process\n",
    "    \n",
    "    Args:\n",
    "        content: Document content as byte string.\n",
    "        mime_type: An IANA MIME type (RFC6838).\n",
    "        skip_human_review: Optional; Whether Human Review feature should be skipped for this request. Default to false.\n",
    "        \n",
    "    Returns:\n",
    "        A dict containing processed document and human_review_status.\n",
    "        See details at\n",
    "        https://cloud.google.com/document-ai/docs/reference/rest/v1/ProcessResponse\n",
    "    \"\"\"\n",
    "    \n",
    "    content_size = len(content)\n",
    "    if content_size > 20*1024*1024:\n",
    "        raise Exception(f\"Content of size {content_size} Bytes is larger than the 20971520 Bytes (20MiB) limit of synchronous processing, please use batch processing.\")\n",
    "    \n",
    "    page_count = 1\n",
    "    \n",
    "    if mime_type == \"image/tiff\":\n",
    "        page_count = Image.open(io.BytesIO(content)).n_frames\n",
    "    \n",
    "    if mime_type == \"application/pdf\":\n",
    "        parser = PDFParser(io.BytesIO(content))\n",
    "        document = PDFDocument(parser)\n",
    "        \n",
    "        # This will give you the count of pages\n",
    "        page_count = resolve1(document.catalog['Pages'])['Count']\n",
    "    \n",
    "    if page_count > 10:\n",
    "        raise Exception(f\"Page count of {page_count} is larger than 10 page limit of synchronous processing, please use batch processing.\")\n",
    "    \n",
    "    # Instantiate a Document AI client\n",
    "    client_options = {\"api_endpoint\": f\"{LOCATION}-documentai.googleapis.com\"}\n",
    "    client = documentai.DocumentProcessorServiceClient(client_options = client_options)\n",
    "    \n",
    "    # The full resource name of the processor, e.g.:\n",
    "    # projects/project-id/locations/location/processor/processor-id\n",
    "    name = f\"projects/{PROJECT_ID}/locations/{LOCATION}/processors/{PROCESSOR_ID}\"\n",
    "    \n",
    "    # Create raw document from image content\n",
    "    raw_document = documentai.RawDocument(\n",
    "        content = content,\n",
    "        mime_type = mime_type\n",
    "    )\n",
    "    \n",
    "    # Process document\n",
    "    process_request = documentai.ProcessRequest(\n",
    "        name = name,\n",
    "        raw_document = raw_document,\n",
    "        skip_human_review = skip_human_review\n",
    "    )\n",
    "    \n",
    "    return client.process_document(request=process_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c82fe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_bounds(page, feature):\n",
    "    # [START vision_document_text_tutorial_detect_bounds]\n",
    "    \"\"\"Returns document bounds given the OCR output page.\"\"\"\n",
    "\n",
    "    bounds = []\n",
    "\n",
    "    # Collect specified feature bounds by enumerating all document features\n",
    "    if (feature == FeatureType.BLOCK):\n",
    "        for block in page.blocks:\n",
    "            if not block.layout.bounding_poly.vertices:\n",
    "                block.layout.bounding_poly.vertices = []\n",
    "                for normalized_vertice in block.layout.bounding_poly.normalized_vertices:\n",
    "                    block.layout.bounding_poly.vertices.append(documentai.Vertex(x=int(normalized_vertice.x * page.image.width),y=int(normalized_vertice.y * page.image.height)))\n",
    "            bounds.append(block.layout.bounding_poly)\n",
    "    if (feature == FeatureType.PARA):\n",
    "        for paragraph in page.paragraphs:\n",
    "            if not paragraph.layout.bounding_poly.vertices:\n",
    "                paragraph.layout.bounding_poly.vertices = []\n",
    "                for normalized_vertice in paragraph.layout.bounding_poly.normalized_vertices:\n",
    "                    paragraph.layout.bounding_poly.vertices.append(documentai.Vertex(x=int(normalized_vertice.x * page.image.width),y=int(normalized_vertice.y * page.image.height)))\n",
    "            bounds.append(paragraph.layout.bounding_poly)\n",
    "    if (feature == FeatureType.LINE):        \n",
    "        for line in page.lines:\n",
    "            if not line.layout.bounding_poly.vertices:\n",
    "                line.layout.bounding_poly.vertices = []\n",
    "                for normalized_vertice in line.layout.bounding_poly.normalized_vertices:\n",
    "                    line.layout.bounding_poly.vertices.append(documentai.Vertex(x=int(normalized_vertice.x * page.image.width),y=int(normalized_vertice.y * page.image.height)))\n",
    "            bounds.append(line.layout.bounding_poly)\n",
    "    if (feature == FeatureType.TOKEN):        \n",
    "        for token in page.tokens:\n",
    "            if not token.layout.bounding_poly.vertices:\n",
    "                token.layout.bounding_poly.vertices = []\n",
    "                for normalized_vertice in token.layout.bounding_poly.normalized_vertices:\n",
    "                    token.layout.bounding_poly.vertices.append(documentai.Vertex(x=int(normalized_vertice.x * page.image.width),y=int(normalized_vertice.y * page.image.height)))\n",
    "            bounds.append(token.layout.bounding_poly)\n",
    "\n",
    "\n",
    "    # The list `bounds` contains the coordinates of the bounding boxes.\n",
    "    # [END vision_document_text_tutorial_detect_bounds]\n",
    "    return bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7c4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(image, bounds, color, width):\n",
    "    \"\"\"Draw a border around the image using the hints in the vector list.\"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for bound in bounds:\n",
    "        points = (\n",
    "            (bound.vertices[0].x, bound.vertices[0].y),\n",
    "            (bound.vertices[1].x, bound.vertices[1].y),\n",
    "            (bound.vertices[2].x, bound.vertices[2].y),\n",
    "            (bound.vertices[3].x, bound.vertices[3].y),\n",
    "            (bound.vertices[0].x, bound.vertices[0].y)\n",
    "        )\n",
    "        draw.line(points,fill=color,width=width,joint='curve')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b927c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_doc_text(page):  \n",
    "    image = Image.open(io.BytesIO(page.image.content))\n",
    "    \n",
    "    # this will draw the bounding boxes for block, paragraph, line and token\n",
    "    bounds = get_page_bounds(page, FeatureType.BLOCK)\n",
    "    draw_boxes(image, bounds, color='blue', width=8)\n",
    "    bounds = get_page_bounds(page, FeatureType.PARA)\n",
    "    draw_boxes(image, bounds, color='red',width=6)\n",
    "    bounds = get_page_bounds(page, FeatureType.LINE)\n",
    "    draw_boxes(image, bounds, color='yellow',width=4)\n",
    "    bounds = get_page_bounds(page, FeatureType.TOKEN)\n",
    "    draw_boxes(image, bounds, color='green',width=2)\n",
    "        \n",
    "    image.show()\n",
    "    \n",
    "    # uncomment if you want to save the image with bounding boxes locally\n",
    "    #image.save(document.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0675e5c9",
   "metadata": {},
   "source": [
    "### Process documents synchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60f5348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gcs_samples():\n",
    "    # Instantiate a Google Cloud Storage Client\n",
    "    storage_client = storage.Client()\n",
    "    \n",
    "    # Sample invoices are stored in gs://cloud-samples-data/documentai/async_invoices/\n",
    "    blobs = storage_client.list_blobs(GCS_INPUT_BUCKET, prefix=GCS_INPUT_PREFIX)\n",
    "    for blob in blobs:\n",
    "        for file_type in SUPPORTED_FILE_TYPES:\n",
    "            if file_type.casefold() in blob.name.casefold():\n",
    "                gcs_input_uri = f\"gs://{GCS_INPUT_BUCKET}/{blob.name}\"\n",
    "                print(f\"Processing {gcs_input_uri}...\")\n",
    "                \n",
    "                mime_type = mimetypes.guess_type(blob.name)[0]\n",
    "                image_content = blob.download_as_string()\n",
    "\n",
    "                try:\n",
    "                    process_response = process(content = image_content, mime_type = mime_type)\n",
    "\n",
    "                    pages = process_response.document.pages\n",
    "                    for page in pages:\n",
    "                        print(f\"Rendering file {blob.name} - Page {page.page_number}/{len(pages)}\")\n",
    "                        render_doc_text(page=page)\n",
    "                except Exception as e: \n",
    "                    print(\"\\x1b[31m\" + str(e) + \"\\x1b[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311a0267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_local_samples():\n",
    "    for path in Path(LOCAL_INPUT_PATH).iterdir():\n",
    "        print(path.resolve())\n",
    "        if path.suffix[1:].casefold() in map(str.casefold, SUPPORTED_FILE_TYPES):\n",
    "            print(f\"Processing {path.name}...\")\n",
    "\n",
    "            mime_type = mimetypes.guess_type(path.name)[0]\n",
    "            image_content = open(path, \"rb\").read()\n",
    "            \n",
    "            try:\n",
    "                process_response = process(content = image_content, mime_type = mime_type)\n",
    "                pages = process_response.document.pages\n",
    "                for page in pages:\n",
    "                    print(f\"Rendering file {path.name} - Page {page.page_number}/{len(pages)}\")\n",
    "                    render_doc_text(page=page)\n",
    "            except Exception as e: \n",
    "                print(\"\\x1b[31m\" + str(e) + \"\\x1b[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfb0822",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_gcs_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff6720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_local_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2d37f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m76",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m76"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
